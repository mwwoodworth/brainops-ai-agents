#!/usr/bin/env python3
"""
Content Generation AI Agent - Multi-AI Orchestrated Blog Factory
================================================================
Enterprise-grade autonomous agent that creates, optimizes, and publishes SEO content
using a multi-AI orchestration pipeline.

Pipeline Stages:
1. RESEARCH (Perplexity) - Real-time web research with statistics and trends
2. WRITING (Claude) - High-quality content generation with Claude Sonnet
3. VISUAL DESIGN (Gemini) - Layout recommendations and image prompts
4. QA (OpenAI GPT-4) - Grammar, SEO, readability, accuracy scoring
5. IMAGE (DALL-E 3) - Hero image generation

This matches the enterprise ERP blog automation capabilities.
"""

import asyncio
import base64
import json
import logging
import os
import re
import uuid
from datetime import datetime, timezone
from typing import Any, Optional
from dataclasses import dataclass, field

import psycopg2
from psycopg2.extras import RealDictCursor
import httpx

from ai_core import ai_core

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class ResearchResult:
    """Research stage output"""
    key_points: list[str] = field(default_factory=list)
    statistics: list[str] = field(default_factory=list)
    trends: list[str] = field(default_factory=list)
    sources: list[str] = field(default_factory=list)
    raw_research: str = ""


@dataclass
class VisualDesign:
    """Visual design stage output"""
    layout_recommendation: str = ""
    hero_image_prompt: str = ""
    color_palette: list[str] = field(default_factory=list)
    typography_suggestion: str = ""
    call_to_action_design: str = ""


@dataclass
class QAResult:
    """QA stage output"""
    score: int = 0  # 0-100
    grammar_issues: list[str] = field(default_factory=list)
    seo_issues: list[str] = field(default_factory=list)
    readability_score: int = 0
    accuracy_notes: list[str] = field(default_factory=list)
    passed: bool = False


@dataclass
class BlogPost:
    """Complete blog post with all metadata"""
    id: str = ""
    title: str = ""
    slug: str = ""
    content: str = ""
    excerpt: str = ""
    featured_image_url: Optional[str] = None
    featured_image_prompt: Optional[str] = None
    seo_metadata: dict = field(default_factory=dict)
    research_data: dict = field(default_factory=dict)
    visual_design: dict = field(default_factory=dict)
    qa_result: dict = field(default_factory=dict)
    models_used: list[str] = field(default_factory=list)
    reading_time_minutes: int = 0
    word_count: int = 0
    status: str = "draft"
    created_at: str = ""
    published_at: Optional[str] = None

# Database configuration - supports DATABASE_URL or individual vars
def _get_db_config():
    """Get database configuration from environment variables."""
    # First try DATABASE_URL (preferred for Render/Supabase)
    database_url = os.getenv('DATABASE_URL')
    if database_url:
        # Parse DATABASE_URL: postgresql://user:pass@host:port/dbname
        match = re.match(
            r'postgresql://([^:]+):([^@]+)@([^:]+):(\d+)/(.+)',
            database_url
        )
        if match:
            return {
                'host': match.group(3),
                'database': match.group(5),
                'user': match.group(1),
                'password': match.group(2),
                'port': int(match.group(4))
            }

    # Fallback to individual environment variables
    db_host = os.getenv("DB_HOST")
    db_name = os.getenv("DB_NAME")
    db_user = os.getenv("DB_USER")
    db_password = os.getenv("DB_PASSWORD")
    db_port = os.getenv("DB_PORT", "5432")

    missing = []
    if not db_host:
        missing.append("DB_HOST")
    if not db_name:
        missing.append("DB_NAME")
    if not db_user:
        missing.append("DB_USER")
    if not db_password:
        missing.append("DB_PASSWORD")

    if missing:
        raise RuntimeError(
            f"Required environment variables not set: {', '.join(missing)}. "
            "Set DATABASE_URL or these variables before using content agent."
        )

    return {
        "host": db_host,
        "database": db_name,
        "user": db_user,
        "password": db_password,
        "port": int(db_port)
    }

def _get_db_connection(**kwargs):
    """Get database connection with validated config."""
    db_config = _get_db_config()
    db_config.update(kwargs)
    return psycopg2.connect(**db_config)

class ContentGeneratorAgent:
    """
    Multi-AI Orchestrated Content Generator

    Uses a 5-stage pipeline matching enterprise ERP capabilities:
    1. Research (Perplexity) - Real-time web research
    2. Writing (Claude) - High-quality content
    3. Visual Design (Gemini) - Layout and image prompts
    4. QA (OpenAI) - Quality scoring
    5. Image (DALL-E 3) - Hero image generation
    """

    _tables_ensured = False

    def __init__(self):
        self.agent_id = str(uuid.uuid4())
        self.agent_name = "ContentGeneratorAgent"
        self.perplexity_key = os.getenv("PERPLEXITY_API_KEY")
        self.openai_key = os.getenv("OPENAI_API_KEY")
        self.models_used = []
        logger.info(f"Initialized {self.agent_name} (Multi-AI Pipeline)")

    # ===== STAGE 1: RESEARCH (Perplexity) =====
    async def _research_stage(self, topic: str, industry: str = "roofing") -> ResearchResult:
        """
        Stage 1: Research with Perplexity AI
        Uses sonar-pro for real-time web research (updated 2026)
        """
        logger.info(f"ðŸ“š Stage 1: Research - {topic}")
        result = ResearchResult()

        if not self.perplexity_key:
            logger.warning("Perplexity API key not found, skipping research stage")
            return result

        logger.info(f"Perplexity key present: {self.perplexity_key[:8]}...")

        try:
            prompt = f"""Research the topic "{topic}" for a {industry} company blog post.

            Provide:
            1. 5 key points that a homeowner would want to know
            2. 3 current statistics or data points (with sources if possible)
            3. 2-3 emerging trends related to this topic

            Return as JSON:
            {{
                "key_points": ["point 1", "point 2", ...],
                "statistics": ["stat 1 (source)", "stat 2 (source)", ...],
                "trends": ["trend 1", "trend 2", ...],
                "sources": ["source 1", "source 2", ...]
            }}"""

            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.perplexity.ai/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.perplexity_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "sonar-pro",  # Updated model name for 2026
                        "messages": [{"role": "user", "content": prompt}],
                        "max_tokens": 2000,
                        "temperature": 0.5
                    },
                    timeout=60.0
                )

                if response.status_code != 200:
                    logger.error(f"Perplexity API error: {response.status_code} - {response.text}")
                    return result

                data = response.json()
                raw_content = data.get("choices", [{}])[0].get("message", {}).get("content", "")

                result.raw_research = raw_content

                # Parse JSON from response
                parsed = ai_core._safe_json(raw_content)
                if isinstance(parsed, dict):
                    result.key_points = parsed.get("key_points", [])
                    result.statistics = parsed.get("statistics", [])
                    result.trends = parsed.get("trends", [])
                    result.sources = parsed.get("sources", [])

                self.models_used.append("perplexity:sonar-pro")
                logger.info(f"âœ… Research complete: {len(result.key_points)} key points, {len(result.statistics)} stats")

        except httpx.HTTPStatusError as e:
            logger.error(f"Research stage HTTP error: {e.response.status_code} - {e.response.text}")
        except Exception as e:
            logger.error(f"Research stage failed: {type(e).__name__}: {e}")

        return result

    # ===== STAGE 2: WRITING (Claude) =====
    async def _writing_stage(self, topic: str, research: ResearchResult, tone: str = "professional") -> str:
        """
        Stage 2: Content Writing with Claude Sonnet
        Uses Claude for high-quality, authoritative content
        """
        logger.info(f"âœï¸ Stage 2: Writing - {topic}")

        research_context = ""
        if research.key_points:
            research_context = f"""
            Based on current research:
            Key Points: {', '.join(research.key_points[:3])}
            Statistics: {', '.join(research.statistics[:2])}
            Trends: {', '.join(research.trends[:2])}
            """

        prompt = f"""Write a comprehensive, SEO-optimized blog post about: "{topic}"

        {research_context}

        Guidelines:
        - Tone: {tone}, trustworthy, expert voice
        - Length: 800-1200 words
        - Format: Markdown with proper H2/H3 headings
        - Structure: Hook intro â†’ 3-4 main sections â†’ CTA conclusion
        - Include: Bullet points, actionable advice, real examples
        - CTA: Encourage booking a free inspection at MyRoofGenius.com
        - SEO: Naturally include the main keyword 3-4 times

        Write ONLY the markdown content, no additional commentary."""

        try:
            content = await ai_core.generate(
                prompt,
                model="claude-3-sonnet-20240229",  # Claude Sonnet for quality
                temperature=0.7,
                max_tokens=3000,
                system_prompt="You are an expert content writer for a roofing company. Write authoritative, helpful content that builds trust and converts readers to customers.",
                prefer_anthropic=True
            )
            self.models_used.append("anthropic:claude-3-sonnet")
            logger.info(f"âœ… Writing complete: {len(content.split())} words")
            return content
        except Exception as e:
            logger.error(f"Writing stage failed: {e}, trying OpenAI fallback")
            # Fallback to OpenAI
            content = await ai_core.generate(
                prompt,
                model="gpt-4-turbo-preview",
                temperature=0.7,
                max_tokens=3000
            )
            self.models_used.append("openai:gpt-4-turbo-preview")
            return content

    # ===== STAGE 3: VISUAL DESIGN (Gemini) =====
    async def _visual_design_stage(self, topic: str, content: str) -> VisualDesign:
        """
        Stage 3: Visual Design with Gemini
        Uses Gemini for layout recommendations and image prompts
        """
        logger.info(f"ðŸŽ¨ Stage 3: Visual Design - {topic}")
        result = VisualDesign()

        prompt = f"""As a visual design expert, create design recommendations for this blog post:

        Topic: {topic}
        Content Preview: {content[:500]}...

        Return as JSON:
        {{
            "layout_recommendation": "description of ideal layout",
            "hero_image_prompt": "detailed DALL-E prompt for hero image (photorealistic, professional)",
            "color_palette": ["#hex1", "#hex2", "#hex3"],
            "typography_suggestion": "font recommendations",
            "call_to_action_design": "CTA button/section design recommendation"
        }}"""

        try:
            response = await ai_core.generate(
                prompt,
                model="gemini-2.0-flash",  # Gemini for visual design
                temperature=0.6,
                max_tokens=1500,
                system_prompt="You are a visual design expert. Output only valid JSON."
            )

            parsed = ai_core._safe_json(response)
            if isinstance(parsed, dict):
                result.layout_recommendation = parsed.get("layout_recommendation", "")
                result.hero_image_prompt = parsed.get("hero_image_prompt", "")
                result.color_palette = parsed.get("color_palette", [])
                result.typography_suggestion = parsed.get("typography_suggestion", "")
                result.call_to_action_design = parsed.get("call_to_action_design", "")

            self.models_used.append("google:gemini-2.0-flash")
            logger.info(f"âœ… Visual design complete: hero image prompt ready")

        except Exception as e:
            logger.error(f"Visual design stage failed: {e}")
            # Generate basic fallback prompt
            result.hero_image_prompt = f"Professional photograph of {topic.lower()}, modern roofing company, clean composition, natural lighting, 4K quality"

        return result

    # ===== STAGE 4: QA (OpenAI GPT-4) =====
    async def _qa_stage(self, content: str, topic: str) -> QAResult:
        """
        Stage 4: Quality Assurance with GPT-4
        Reviews grammar, SEO, readability, and accuracy
        """
        logger.info(f"ðŸ” Stage 4: QA Review - {topic}")
        result = QAResult()

        prompt = f"""As a professional content reviewer, analyze this blog post:

        Topic: {topic}
        Content:
        {content[:3000]}

        Evaluate and return JSON:
        {{
            "overall_score": 0-100,
            "grammar_issues": ["issue 1", ...] or [],
            "seo_issues": ["issue 1", ...] or [],
            "readability_score": 0-100,
            "accuracy_notes": ["note 1", ...] or [],
            "passed": true/false (true if score >= 75)
        }}"""

        try:
            response = await ai_core.generate(
                prompt,
                model="gpt-4-turbo-preview",  # GPT-4 for QA
                temperature=0.3,  # Lower temp for consistent evaluation
                max_tokens=1000,
                system_prompt="You are a professional content editor. Be thorough but fair. Output only valid JSON."
            )

            parsed = ai_core._safe_json(response)
            if isinstance(parsed, dict):
                result.score = parsed.get("overall_score", 0)
                result.grammar_issues = parsed.get("grammar_issues", [])
                result.seo_issues = parsed.get("seo_issues", [])
                result.readability_score = parsed.get("readability_score", 0)
                result.accuracy_notes = parsed.get("accuracy_notes", [])
                result.passed = parsed.get("passed", False)

            self.models_used.append("openai:gpt-4-turbo-preview")
            logger.info(f"âœ… QA complete: Score {result.score}/100, Passed: {result.passed}")

        except Exception as e:
            logger.error(f"QA stage failed: {e}")
            result.score = 70
            result.passed = True

        return result

    # ===== STAGE 5: IMAGE GENERATION (DALL-E 3 with Gemini Fallback) =====
    async def _image_stage(self, image_prompt: str) -> Optional[str]:
        """
        Stage 5: Hero Image Generation
        Primary: DALL-E 3
        Fallback: Gemini Imagen 3
        Returns the image URL
        """
        logger.info(f"ðŸ–¼ï¸ Stage 5: Image Generation")
        logger.info(f"Image prompt: {image_prompt[:100]}...")

        # Try DALL-E 3 first
        image_url = await self._generate_dalle_image(image_prompt)
        if image_url:
            return image_url

        # Fallback to Gemini Imagen
        logger.info("ðŸ”„ DALL-E failed, trying Gemini Imagen fallback...")
        image_url = await self._generate_gemini_image(image_prompt)
        if image_url:
            return image_url

        logger.warning("Both DALL-E and Gemini image generation failed")
        return None

    async def _generate_dalle_image(self, image_prompt: str) -> Optional[str]:
        """Generate image with DALL-E 3"""
        if not self.openai_key:
            logger.warning("OpenAI API key not found, skipping DALL-E")
            return None

        logger.info(f"Trying DALL-E 3 (key: {self.openai_key[:8]}...)")

        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/images/generations",
                    headers={
                        "Authorization": f"Bearer {self.openai_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "dall-e-3",
                        "prompt": image_prompt,
                        "n": 1,
                        "size": "1792x1024",
                        "quality": "hd",
                        "style": "natural"
                    },
                    timeout=120.0
                )

                if response.status_code != 200:
                    error_data = response.json() if response.text else {}
                    error_msg = error_data.get("error", {}).get("message", response.text)
                    logger.error(f"DALL-E API error: {response.status_code} - {error_msg}")
                    return None

                data = response.json()
                image_url = data.get("data", [{}])[0].get("url")

                if not image_url:
                    logger.error(f"No image URL in DALL-E response")
                    return None

                self.models_used.append("openai:dall-e-3")
                logger.info(f"âœ… DALL-E image generated: {image_url[:50]}...")
                return image_url

        except Exception as e:
            logger.error(f"DALL-E generation failed: {type(e).__name__}: {e}")
            return None

    async def _generate_gemini_image(self, image_prompt: str) -> Optional[str]:
        """Generate image with Gemini Imagen 3"""
        gemini_key = os.getenv("GOOGLE_AI_API_KEY")
        if not gemini_key:
            logger.warning("Google AI API key not found, skipping Gemini Imagen")
            return None

        logger.info(f"Trying Gemini Imagen 3 (key: {gemini_key[:8]}...)")

        try:
            async with httpx.AsyncClient() as client:
                # Gemini Imagen 3 API endpoint
                response = await client.post(
                    f"https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-generate-002:predict?key={gemini_key}",
                    headers={"Content-Type": "application/json"},
                    json={
                        "instances": [{"prompt": image_prompt}],
                        "parameters": {
                            "sampleCount": 1,
                            "aspectRatio": "16:9",
                            "personGeneration": "dont_allow",
                            "safetySetting": "block_medium_and_above"
                        }
                    },
                    timeout=120.0
                )

                if response.status_code != 200:
                    error_text = response.text[:500] if response.text else "No error details"
                    logger.error(f"Gemini Imagen API error: {response.status_code} - {error_text}")
                    return None

                data = response.json()
                predictions = data.get("predictions", [])

                if not predictions:
                    logger.error(f"No predictions in Gemini Imagen response")
                    return None

                # Gemini returns base64 image data - we need to save it and return URL
                image_data = predictions[0].get("bytesBase64Encoded")
                if not image_data:
                    logger.error("No image data in Gemini response")
                    return None

                # For now, we'll store the base64 data directly in the response
                # In production, you'd upload this to a storage service
                self.models_used.append("google:imagen-3")
                logger.info(f"âœ… Gemini Imagen generated image successfully")

                # Return as data URL for now (can be displayed directly in HTML)
                return f"data:image/png;base64,{image_data}"

        except Exception as e:
            logger.error(f"Gemini Imagen generation failed: {type(e).__name__}: {e}")
            return None

    def _ensure_tables(self):
        """Verify required tables exist (DDL removed â€” agent_worker has no DDL permissions)."""
        required_tables = [
                "content_posts",
        ]
        try:
            from database.verify_tables import verify_tables_sync
            conn = psycopg2.connect(**_get_db_config())
            cursor = conn.cursor()
            ok = verify_tables_sync(required_tables, cursor, module_name="content_generation_agent")
            cursor.close()
            conn.close()
            if not ok:
                return
            self._tables_initialized = True
        except Exception as exc:
            logger.error("Table verification failed: %s", exc)
    async def execute(self, task: dict[str, Any]) -> dict[str, Any]:
        """Execute content generation task"""
        self._ensure_tables()
        action = task.get('action', 'generate_blog')

        if action == 'generate_blog':
            return await self.generate_blog_post(task)
        elif action == 'generate_topic_ideas':
            return await self.generate_topic_ideas(task)
        else:
            return {"status": "error", "error": f"Unknown action: {action}"}

    async def generate_topic_ideas(self, task: dict) -> dict:
        """Generate blog topic ideas based on industry trends"""
        try:
            industry = task.get("industry", "roofing")
            count = task.get("count", 5)

            prompt = f"""Generate {count} engaging blog post topics for a {industry} company.
            Focus on topics that drive leads, answer common customer questions, and build trust.
            Include a suggested SEO keyword for each.
            
            Return ONLY a JSON array of objects with keys: topic, keyword, target_audience."""

            response = await ai_core.generate(
                prompt,
                model="gpt-4-turbo-preview",
                temperature=0.7,
                system_prompt="You are an SEO content strategist. Output only valid JSON."
            )

            # Use ai_core's safe json parsing if response is string
            if isinstance(response, str):
                topics = ai_core._safe_json(response)
                # If _safe_json returns dict but we expect list, try to find list inside
                if isinstance(topics, dict):
                    # Check if it wrapped in a key like "topics"
                    for key in topics:
                        if isinstance(topics[key], list):
                            topics = topics[key]
                            break
            else:
                topics = response

            return {"status": "completed", "topics": topics}

        except Exception as e:
            logger.error(f"Topic generation failed: {e}")
            return {"status": "error", "error": str(e)}

    async def generate_blog_post(self, task: dict) -> dict:
        """
        Generate a full blog post using the 5-stage Multi-AI Pipeline

        Stages:
        1. Research (Perplexity) - Real-time web research
        2. Writing (Claude) - High-quality content
        3. Visual Design (Gemini) - Layout and image prompts
        4. QA (OpenAI GPT-4) - Quality scoring
        5. Image (DALL-E 3) - Hero image generation
        """
        try:
            self.models_used = []  # Reset for this generation
            topic = task.get("topic")
            industry = task.get("industry", "roofing")
            tone = task.get("tone", "professional")
            include_image = task.get("include_image", True)

            if not topic:
                # Auto-generate a topic if none provided
                topics_result = await self.generate_topic_ideas({"count": 1})
                if topics_result.get("topics") and isinstance(topics_result["topics"], list) and len(topics_result["topics"]) > 0:
                    topic = topics_result["topics"][0].get("topic")
                else:
                    topic = "The Importance of Regular Roof Inspections"

            logger.info(f"ðŸš€ Starting Multi-AI Blog Pipeline for: {topic}")
            start_time = datetime.now(timezone.utc)

            # ===== STAGE 1: RESEARCH =====
            research = await self._research_stage(topic, industry)

            # ===== STAGE 2: WRITING =====
            content = await self._writing_stage(topic, research, tone)

            # ===== STAGE 3: VISUAL DESIGN =====
            visual_design = await self._visual_design_stage(topic, content)

            # ===== STAGE 4: QA =====
            qa_result = await self._qa_stage(content, topic)

            # ===== STAGE 5: IMAGE GENERATION =====
            image_url = None
            if include_image and visual_design.hero_image_prompt:
                image_url = await self._image_stage(visual_design.hero_image_prompt)

            # Generate SEO Metadata
            seo_prompt = f"""Generate SEO metadata for this blog post:
            Topic: {topic}

            Return JSON with:
            - meta_title (max 60 chars)
            - meta_description (max 160 chars)
            - slug (url-friendly)
            - keywords (array of 5-7 keywords)"""

            seo_response = await ai_core.generate(
                seo_prompt,
                model="gpt-3.5-turbo",
                system_prompt="Output only valid JSON."
            )

            if isinstance(seo_response, str):
                seo_data = ai_core._safe_json(seo_response)
            else:
                seo_data = seo_response

            # Calculate word count and reading time
            word_count = len(content.split())
            reading_time = max(1, word_count // 200)  # Avg 200 words per minute

            # Create excerpt
            excerpt = seo_data.get("meta_description", content[:200].split(".")[0] + "...")

            # Build comprehensive post data
            requested_status = task.get("status", "published")
            final_status = requested_status
            if requested_status == "published" and not qa_result.passed:
                final_status = "review"

            post_data = BlogPost(
                title=topic,
                slug=seo_data.get("slug", ""),
                content=content,
                excerpt=excerpt,
                featured_image_url=image_url,
                featured_image_prompt=visual_design.hero_image_prompt,
                seo_metadata=seo_data,
                research_data={
                    "key_points": research.key_points,
                    "statistics": research.statistics,
                    "trends": research.trends,
                    "sources": research.sources
                },
                visual_design={
                    "layout": visual_design.layout_recommendation,
                    "color_palette": visual_design.color_palette,
                    "typography": visual_design.typography_suggestion,
                    "cta_design": visual_design.call_to_action_design
                },
                qa_result={
                    "score": qa_result.score,
                    "readability": qa_result.readability_score,
                    "passed": qa_result.passed,
                    "grammar_issues": qa_result.grammar_issues,
                    "seo_issues": qa_result.seo_issues
                },
                models_used=self.models_used,
                word_count=word_count,
                reading_time_minutes=reading_time,
                status=final_status,
                created_at=datetime.now(timezone.utc).isoformat()
            )

            # Publish to Database
            post_id = await self._publish_post_enhanced(post_data)
            post_data.id = post_id

            duration = (datetime.now(timezone.utc) - start_time).total_seconds()

            logger.info(f"âœ… Multi-AI Pipeline Complete: {topic}")
            logger.info(f"   ðŸ“Š QA Score: {qa_result.score}/100 | Words: {word_count} | Duration: {duration:.1f}s")
            logger.info(f"   ðŸ¤– Models Used: {', '.join(self.models_used)}")

            return {
                "status": "completed",
                "post_id": post_id,
                "title": topic,
                "slug": seo_data.get("slug"),
                "url": f"https://myroofgenius.com/blog/{seo_data.get('slug')}",
                "word_count": word_count,
                "reading_time_minutes": reading_time,
                "qa_score": qa_result.score,
                "qa_passed": qa_result.passed,
                "post_status": final_status,
                "image_generated": image_url is not None,
                "models_used": self.models_used,
                "duration_seconds": duration,
                "pipeline": "multi-ai-5-stage"
            }

        except Exception as e:
            logger.error(f"Multi-AI Blog Pipeline failed: {e}")
            return {"status": "error", "error": str(e), "models_used": self.models_used}

    async def _publish_post_enhanced(self, post: BlogPost) -> str:
        """Save enhanced post to database with all metadata"""
        try:
            conn = _get_db_connection()
            cursor = conn.cursor()

            # Ensure slug is unique
            slug = post.slug
            if not slug:
                slug = post.title.lower().replace(" ", "-")
                slug = re.sub(r"[^a-z0-9-]", "", slug)

            cursor.execute("SELECT id FROM content_posts WHERE slug = %s", (slug,))
            if cursor.fetchone():
                slug = f"{slug}-{uuid.uuid4().hex[:6]}"

            cursor.execute("""
                INSERT INTO content_posts
                (title, slug, content, excerpt, status, seo_metadata, metrics, published_at)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                RETURNING id
            """, (
                post.title,
                slug,
                post.content,
                post.excerpt,
                post.status,
                json.dumps({
                    **post.seo_metadata,
                    "featured_image_url": post.featured_image_url,
                    "featured_image_prompt": post.featured_image_prompt
                }),
                json.dumps({
                    "research_data": post.research_data,
                    "visual_design": post.visual_design,
                    "qa_result": post.qa_result,
                    "models_used": post.models_used,
                    "word_count": post.word_count,
                    "reading_time_minutes": post.reading_time_minutes,
                    "pipeline": "multi-ai-5-stage"
                }),
                datetime.now(timezone.utc) if post.status == 'published' else None
            ))

            post_id = cursor.fetchone()[0]
            conn.commit()
            cursor.close()
            conn.close()

            logger.info(f"ðŸ“ Published enhanced post: {post.title} ({post_id})")
            return str(post_id)

        except Exception as e:
            logger.error(f"Database publish failed: {e}")
            raise e

    async def _publish_post(self, title: str, content: str, seo_data: dict, status: str) -> str:
        """Save post to database"""
        try:
            conn = _get_db_connection()
            cursor = conn.cursor()

            # Ensure slug is unique
            slug = seo_data.get("slug")
            if not slug:
                 slug = title.lower().replace(" ", "-").replace(r"[^a-z0-9-]", "")

            cursor.execute("SELECT id FROM content_posts WHERE slug = %s", (slug,))
            if cursor.fetchone():
                slug = f"{slug}-{uuid.uuid4().hex[:6]}"

            cursor.execute("""
                INSERT INTO content_posts
                (title, slug, content, excerpt, status, seo_metadata, published_at)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
                RETURNING id
            """, (
                title,
                slug,
                content,
                seo_data.get("meta_description"),
                status,
                json.dumps(seo_data),
                datetime.now(timezone.utc) if status == 'published' else None
            ))

            post_id = cursor.fetchone()[0]
            conn.commit()
            cursor.close()
            conn.close()
            
            logger.info(f"Published post: {title} ({post_id})")
            return str(post_id)

        except Exception as e:
            logger.error(f"Database publish failed: {e}")
            raise e

if __name__ == "__main__":
    # Test run
    agent = ContentGeneratorAgent()
    asyncio.run(agent.execute({"action": "generate_blog", "topic": "5 Signs Your Roof Needs Replacement"}))
