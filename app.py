from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
import os
import asyncio
import logging
from datetime import datetime
from typing import Dict, Any, Optional, List
import json
import psycopg2
from psycopg2.extras import RealDictCursor
import uuid

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Build timestamp for cache busting
BUILD_TIME = "2025-09-17T22:10:00Z"  # SYNC VERSION
logger.info(f"ðŸš€ Starting BrainOps AI v4.0.4 - Build: {BUILD_TIME}")

# Import REAL AI Core with error handling
try:
    from ai_core import RealAICore, ai_generate, ai_analyze
    # Initialize REAL AI
    ai_core = RealAICore()
    AI_AVAILABLE = True
    logger.info("âœ… Real AI Core initialized successfully")
except Exception as e:
    logger.error(f"âŒ AI Core initialization failed: {e}")
    AI_AVAILABLE = False
    ai_core = None

# Initialize FastAPI app
app = FastAPI(
    title="BrainOps AI Agents - REAL AI v4.0.3",
    description="Production AI System with GPT-4 & Claude",
    version="4.0.4"  # Synchronous AI for stability
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Database configuration
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'aws-0-us-east-2.pooler.supabase.com'),
    'database': os.getenv('DB_NAME', 'postgres'),
    'user': os.getenv('DB_USER', 'postgres.yomagoqdmxszqtdwuhab'),
    'password': os.getenv('DB_PASSWORD', 'REDACTED_SUPABASE_DB_PASSWORD'),
    'port': int(os.getenv('DB_PORT', 5432))
}

# Log configuration for debugging
logger.info(f"Database config - Host: {DB_CONFIG['host']}, User: {DB_CONFIG['user'][:10]}..., Port: {DB_CONFIG['port']}")

def get_db_connection():
    """Get database connection with error handling"""
    try:
        # Ensure we have valid config
        if not DB_CONFIG.get('host') or not DB_CONFIG.get('user') or not DB_CONFIG.get('password'):
            logger.error(f"Missing database configuration. Host: {bool(DB_CONFIG.get('host'))}, User: {bool(DB_CONFIG.get('user'))}, Password: {bool(DB_CONFIG.get('password'))}")
            return None
        conn = psycopg2.connect(**DB_CONFIG)
        return conn
    except Exception as e:
        logger.error(f"Database connection failed: {e}")
        return None

# Global error handler
@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    logger.error(f"Global error: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "message": str(exc),
            "path": str(request.url.path)
        }
    )

# UUID validation middleware
@app.middleware("http")
async def validate_uuids(request: Request, call_next):
    """Validate and fix UUID parameters"""
    if request.method in ["POST", "PUT", "PATCH"]:
        try:
            body = await request.body()
            if body:
                data = json.loads(body)
                # Fix common UUID issues
                for key in ['id', 'user_id', 'customer_id', 'lead_id', 'agent_id']:
                    if key in data:
                        value = data[key]
                        if value == "test" or value == "undefined" or value == "null":
                            data[key] = str(uuid.uuid4())
                        elif isinstance(value, str) and len(value) != 36:
                            data[key] = str(uuid.uuid4())

                # Create new request with fixed data
                from starlette.datastructures import Headers
                from starlette.requests import Request as StarletteRequest

                scope = request.scope
                scope["body"] = json.dumps(data).encode()
                request = StarletteRequest(scope, request.receive)
        except:
            pass

    response = await call_next(request)
    return response

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "service": "BrainOps AI Agents",
        "version": "3.5.1",
        "status": "operational",
        "endpoints": [
            "/health",
            "/agents",
            "/ai/status",
            "/ai/analyze",
            "/memory/store",
            "/memory/retrieve"
        ]
    }

@app.get("/health")
async def health():
    """Health check endpoint with AI status"""
    conn = get_db_connection()
    db_status = "connected" if conn else "disconnected"
    if conn:
        conn.close()

    return {
        "status": "healthy" if AI_AVAILABLE else "degraded",
        "version": "4.0.4",
        "build": BUILD_TIME,
        "database": db_status,
        "ai_enabled": AI_AVAILABLE,
        "features": {
            "real_ai": AI_AVAILABLE,
            "gpt4": AI_AVAILABLE and bool(os.getenv("OPENAI_API_KEY")),
            "claude": AI_AVAILABLE and bool(os.getenv("ANTHROPIC_API_KEY")),
            "ai_agents": True,
            "memory_system": True,
            "workflow_engine": True,
            "ab_testing": True,
            "performance_optimization": True,
            "failover_redundancy": True,
            "multi_region": True,
            "ai_operating_system": True
        },
        "timestamp": datetime.utcnow().isoformat()
    }

@app.get("/agents")
async def get_agents():
    """Get all AI agents"""
    conn = get_db_connection()
    if not conn:
        raise HTTPException(status_code=503, detail="Database unavailable")

    try:
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        cursor.execute("""
            SELECT id, name, type, status, capabilities, created_at
            FROM ai_agents
            WHERE status = 'active'
            ORDER BY created_at DESC
            LIMIT 100
        """)
        agents = cursor.fetchall()

        # Convert to JSON-serializable format
        for agent in agents:
            agent['id'] = str(agent['id'])
            agent['created_at'] = agent['created_at'].isoformat() if agent['created_at'] else None

        cursor.close()
        conn.close()

        return {
            "agents": agents,
            "count": len(agents),
            "status": "success"
        }
    except Exception as e:
        if conn:
            conn.close()
        logger.error(f"Error fetching agents: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/agents/active")
async def get_active_agents():
    """Get active agent count"""
    conn = get_db_connection()
    if not conn:
        return {"count": 0, "status": "database_error"}

    try:
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM ai_agents WHERE status = 'active'")
        count = cursor.fetchone()[0]
        cursor.close()
        conn.close()
        return {"count": count, "status": "success"}
    except:
        if conn:
            conn.close()
        return {"count": 0, "status": "error"}

@app.get("/ai/status")
async def ai_status():
    """AI system status with diagnostics"""
    conn = get_db_connection()
    if not conn:
        return {"status": "degraded", "database": "disconnected", "ai_available": AI_AVAILABLE}

    try:
        cursor = conn.cursor(cursor_factory=RealDictCursor)

        # Get system metrics
        cursor.execute("""
            SELECT
                (SELECT COUNT(*) FROM ai_agents WHERE status = 'active') as active_agents,
                (SELECT COUNT(*) FROM agent_executions WHERE created_at > NOW() - INTERVAL '1 hour') as recent_executions,
                (SELECT COUNT(*) FROM ai_master_context) as memory_entries
        """)
        metrics = cursor.fetchone()

        cursor.close()
        conn.close()

        # Check API key status
        api_status = {
            "openai_configured": bool(os.getenv("OPENAI_API_KEY")),
            "anthropic_configured": bool(os.getenv("ANTHROPIC_API_KEY")),
            "ai_core_initialized": AI_AVAILABLE
        }

        return {
            "status": "operational" if AI_AVAILABLE else "degraded",
            "ai_available": AI_AVAILABLE,
            "api_status": api_status,
            "metrics": metrics,
            "timestamp": datetime.utcnow().isoformat(),
            "version": "4.0.0" if AI_AVAILABLE else "3.5.1"
        }
    except Exception as e:
        if conn:
            conn.close()
        return {"status": "error", "message": str(e), "ai_available": AI_AVAILABLE}

@app.post("/ai/test")
async def ai_test(request: Dict[str, Any]):
    """Simple AI test endpoint - using sync version"""
    try:
        from ai_core_sync import sync_ai_core

        prompt = request.get('prompt', 'Say hello')
        logger.info(f"AI test with prompt: {prompt}")

        # Use synchronous version to avoid async issues
        result = sync_ai_core.generate(
            prompt=prompt,
            model="gpt-3.5-turbo",
            max_tokens=20
        )

        return {
            "success": True,
            "result": result,
            "model": "gpt-3.5-turbo"
        }
    except Exception as e:
        logger.error(f"AI test error: {e}")
        return {
            "success": False,
            "error": str(e),
            "details": "Using sync version"
        }

@app.post("/ai/analyze")
async def ai_analyze_endpoint(request: Dict[str, Any]):
    """REAL AI analysis endpoint - Uses GPT-4/Claude"""
    # Validate input
    if not request.get('prompt'):
        raise HTTPException(status_code=400, detail="Prompt required")

    # Check if AI is available
    if not AI_AVAILABLE or not ai_core:
        logger.error("AI Core not available - check API keys")
        return {
            "analysis_id": str(uuid.uuid4()),
            "status": "degraded",
            "result": "AI service temporarily unavailable. Please check API key configuration.",
            "model": "unavailable",
            "timestamp": datetime.utcnow().isoformat()
        }

    conn = get_db_connection()
    if not conn:
        raise HTTPException(status_code=503, detail="Database unavailable")

    try:
        # Get REAL AI analysis
        context = request.get('context', {})
        model = request.get('model', 'gpt-4')

        # Try synchronous version for stability
        try:
            from ai_core_sync import sync_ai_core

            # Use sync version
            result = sync_ai_core.generate(
                prompt=request['prompt'],
                model=model,
                temperature=request.get('temperature', 0.7),
                max_tokens=request.get('max_tokens', 2000),
                system_prompt="You are an expert AI assistant for a roofing business." if 'roof' in request['prompt'].lower() else None
            )
        except:
            # Fallback to async if sync fails
            result = await ai_core.generate(
                prompt=request['prompt'],
                model=model,
                temperature=request.get('temperature', 0.7),
                max_tokens=request.get('max_tokens', 2000)
            )

        # Store in database
        cursor = conn.cursor()
        analysis_id = str(uuid.uuid4())
        cursor.execute("""
            INSERT INTO agent_executions (id, agent_type, prompt, response, status, created_at)
            VALUES (%s, %s, %s, %s, %s, NOW())
        """, (analysis_id, 'ai_analyzer', request['prompt'], json.dumps(result) if isinstance(result, dict) else result, 'completed'))

        # Log AI usage
        ai_core.log_usage(request['prompt'], str(result), model)

        conn.commit()
        cursor.close()
        conn.close()

        return {
            "analysis_id": analysis_id,
            "status": "completed",
            "result": result,  # REAL AI RESPONSE
            "model": model,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        if conn:
            conn.rollback()
            conn.close()
        logger.error(f"AI Analysis error: {e}")
        # Try fallback model if primary fails
        try:
            result = await ai_generate(request['prompt'], model='gpt-3.5-turbo')
            return {
                "analysis_id": str(uuid.uuid4()),
                "status": "completed_with_fallback",
                "result": result,
                "model": "gpt-3.5-turbo",
                "timestamp": datetime.utcnow().isoformat()
            }
        except:
            raise HTTPException(status_code=500, detail=str(e))

@app.post("/memory/store")
async def store_memory(request: Dict[str, Any]):
    """Store memory endpoint"""
    conn = get_db_connection()
    if not conn:
        raise HTTPException(status_code=503, detail="Database unavailable")

    try:
        cursor = conn.cursor()
        memory_id = str(uuid.uuid4())

        cursor.execute("""
            INSERT INTO ai_master_context (
                id, context_type, context_key, context_value,
                importance, is_critical, created_at
            ) VALUES (%s, %s, %s, %s, %s, %s, NOW())
            ON CONFLICT (context_type, context_key)
            DO UPDATE SET
                context_value = EXCLUDED.context_value,
                updated_at = NOW()
            RETURNING id
        """, (
            memory_id,
            request.get('type', 'general'),
            request.get('key', str(uuid.uuid4())),
            json.dumps(request.get('value', {})),
            request.get('importance', 5),
            request.get('is_critical', False)
        ))

        result_id = cursor.fetchone()[0]
        conn.commit()
        cursor.close()
        conn.close()

        return {
            "memory_id": str(result_id),
            "status": "stored",
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        if conn:
            conn.rollback()
            conn.close()
        logger.error(f"Memory store error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/memory/retrieve")
async def retrieve_memory(context_type: Optional[str] = None, limit: int = 10):
    """Retrieve memory endpoint"""
    conn = get_db_connection()
    if not conn:
        raise HTTPException(status_code=503, detail="Database unavailable")

    try:
        cursor = conn.cursor(cursor_factory=RealDictCursor)

        if context_type:
            cursor.execute("""
                SELECT id, context_type, context_key, context_value, importance, created_at
                FROM ai_master_context
                WHERE context_type = %s
                ORDER BY importance DESC, created_at DESC
                LIMIT %s
            """, (context_type, limit))
        else:
            cursor.execute("""
                SELECT id, context_type, context_key, context_value, importance, created_at
                FROM ai_master_context
                ORDER BY importance DESC, created_at DESC
                LIMIT %s
            """, (limit,))

        memories = cursor.fetchall()

        # Convert to JSON-serializable format
        for memory in memories:
            memory['id'] = str(memory['id'])
            memory['created_at'] = memory['created_at'].isoformat() if memory['created_at'] else None

        cursor.close()
        conn.close()

        return {
            "memories": memories,
            "count": len(memories),
            "status": "success"
        }
    except Exception as e:
        if conn:
            conn.close()
        logger.error(f"Memory retrieve error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/workflow/execute")
async def execute_workflow(request: Dict[str, Any]):
    """Execute workflow endpoint"""
    workflow_id = str(uuid.uuid4())

    return {
        "workflow_id": workflow_id,
        "status": "initiated",
        "workflow_type": request.get('type', 'default'),
        "timestamp": datetime.utcnow().isoformat()
    }

@app.get("/performance/metrics")
async def get_performance_metrics():
    """Get performance metrics"""
    conn = get_db_connection()
    if not conn:
        return {"status": "database_error", "metrics": {}}

    try:
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        cursor.execute("""
            SELECT
                AVG(response_time_ms) as avg_response_time,
                COUNT(*) as total_requests,
                SUM(CASE WHEN status_code < 400 THEN 1 ELSE 0 END) as successful_requests
            FROM performance_metrics
            WHERE timestamp > NOW() - INTERVAL '1 hour'
        """)
        metrics = cursor.fetchone()
        cursor.close()
        conn.close()

        return {
            "status": "success",
            "metrics": metrics or {"avg_response_time": 0, "total_requests": 0}
        }
    except:
        if conn:
            conn.close()
        return {"status": "error", "metrics": {}}

@app.post("/ai/chat")
async def ai_chat(request: Dict[str, Any]):
    """REAL AI Chat endpoint - Conversational AI with GPT-4/Claude"""
    messages = request.get('messages', [])
    if not messages:
        raise HTTPException(status_code=400, detail="Messages required")

    try:
        # Get conversation context
        context = request.get('context', {})
        response = await ai_core.chat_with_context(messages, context)

        return {
            "response": response,
            "model": "gpt-4-turbo-preview",
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Chat error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/generate")
async def ai_generate_endpoint(request: Dict[str, Any]):
    """REAL AI Generation - Direct LLM access"""
    prompt = request.get('prompt')
    if not prompt:
        raise HTTPException(status_code=400, detail="Prompt required")

    try:
        result = await ai_core.generate(
            prompt=prompt,
            model=request.get('model', 'gpt-4'),
            temperature=request.get('temperature', 0.7),
            max_tokens=request.get('max_tokens', 2000),
            system_prompt=request.get('system_prompt'),
            stream=request.get('stream', False)
        )

        if request.get('stream'):
            return StreamingResponse(result)

        return {
            "result": result,
            "model": request.get('model', 'gpt-4'),
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Generation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/embeddings")
async def ai_embeddings(request: Dict[str, Any]):
    """Generate REAL embeddings for vector search"""
    text = request.get('text')
    if not text:
        raise HTTPException(status_code=400, detail="Text required")

    try:
        embeddings = await ai_core.generate_embeddings(text)

        # Store in vector database
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT INTO ai_persistent_memory (
                    memory_type, memory_key, memory_value, embedding, created_at
                ) VALUES ('embedding', %s, %s, %s, NOW())
            """, (str(uuid.uuid4()), json.dumps({"text": text}), embeddings))
            conn.commit()
            cursor.close()
            conn.close()

        return {
            "embeddings": embeddings[:10] + ["..."],  # Return sample for verification
            "dimensions": len(embeddings),
            "model": "text-embedding-3-small",
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Embedding error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/score-lead")
async def ai_score_lead(request: Dict[str, Any]):
    """REAL AI Lead Scoring"""
    lead_data = request.get('lead_data')
    if not lead_data:
        raise HTTPException(status_code=400, detail="Lead data required")

    try:
        result = await ai_core.score_lead(lead_data)

        # Store in database
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor()
            cursor.execute("""
                INSERT INTO lead_scores (
                    lead_id, score, reasoning, recommendations, created_at
                ) VALUES (%s, %s, %s, %s, NOW())
            """, (
                lead_data.get('id', str(uuid.uuid4())),
                result.get('score', 0),
                result.get('reasoning', ''),
                json.dumps(result.get('recommendations', []))
            ))
            conn.commit()
            cursor.close()
            conn.close()

        return result
    except Exception as e:
        logger.error(f"Lead scoring error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/generate-proposal")
async def ai_generate_proposal(request: Dict[str, Any]):
    """REAL AI Proposal Generation"""
    customer_data = request.get('customer_data')
    job_data = request.get('job_data')

    if not customer_data or not job_data:
        raise HTTPException(status_code=400, detail="Customer and job data required")

    try:
        proposal = await ai_core.generate_proposal(customer_data, job_data)

        # Store in database
        conn = get_db_connection()
        if conn:
            cursor = conn.cursor()
            proposal_id = str(uuid.uuid4())
            cursor.execute("""
                INSERT INTO proposals (
                    id, customer_id, content, status, created_at
                ) VALUES (%s, %s, %s, 'draft', NOW())
            """, (
                proposal_id,
                customer_data.get('id', str(uuid.uuid4())),
                proposal
            ))
            conn.commit()
            cursor.close()
            conn.close()

        return {
            "proposal_id": proposal_id,
            "content": proposal,
            "model": "gpt-4",
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Proposal generation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/optimize-schedule")
async def ai_optimize_schedule(request: Dict[str, Any]):
    """REAL AI Schedule Optimization"""
    jobs = request.get('jobs', [])
    crews = request.get('crews', [])

    if not jobs:
        raise HTTPException(status_code=400, detail="Jobs required")

    try:
        result = await ai_core.optimize_schedule(jobs, crews)

        return {
            "schedule": result,
            "optimized": True,
            "model": "gpt-4",
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Schedule optimization error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/ai/analyze-image")
async def ai_analyze_image(request: Dict[str, Any]):
    """REAL AI Image Analysis with GPT-4 Vision"""
    image_url = request.get('image_url')
    prompt = request.get('prompt', "Analyze this image and describe what you see.")

    if not image_url:
        raise HTTPException(status_code=400, detail="Image URL required")

    try:
        analysis = await ai_core.analyze_image(image_url, prompt)

        return {
            "analysis": analysis,
            "model": "gpt-4-vision-preview",
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        logger.error(f"Image analysis error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/ab-test/experiments")
async def get_experiments():
    """Get A/B test experiments"""
    conn = get_db_connection()
    if not conn:
        return {"experiments": [], "status": "database_error"}

    try:
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        cursor.execute("""
            SELECT id, name, status, created_at
            FROM ab_test_experiments
            WHERE status = 'running'
            ORDER BY created_at DESC
            LIMIT 10
        """)
        experiments = cursor.fetchall()

        for exp in experiments:
            exp['id'] = str(exp['id'])
            exp['created_at'] = exp['created_at'].isoformat() if exp['created_at'] else None

        cursor.close()
        conn.close()

        return {"experiments": experiments, "status": "success"}
    except:
        if conn:
            conn.close()
        return {"experiments": [], "status": "error"}

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)
